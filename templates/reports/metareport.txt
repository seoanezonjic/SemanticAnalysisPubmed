<%
    import numpy as np
    import pandas as pd
    import copy
    import pprint

    global color_legend

    ##### FUNCTIONS 
    def transform_from_long_to_wide(table, topk_order_dict):
        df = pd.DataFrame(table, columns = ["topk", "dist", "dataset", "doc_type", "bench_type"])
        pivoted = pd.pivot_table(df, index='topk', columns=['dataset', 'doc_type', 'bench_type'], values='dist', margins=False)
        pivoted = pivoted.rename(columns={"do":"do", "ehrhart":"ehrhart"})
        pivoted = pivoted.sort_values(by='topk', key=lambda x: x.map(topk_order_dict))
        var_attr_names = ["dataset", "doc_type", "bench_type"]
        var_attr = [[var_attr_names[idx]]+list(subl) for idx, subl in enumerate(zip(*[i for i in pivoted.columns])) ]
        rows = [[i for i in row] for row in pivoted.itertuples()]
        new_header = [["topK"] + [f"sample{i}" for i in range(1,len(rows[0]))]]
        new_table = new_header + var_attr + rows
        return new_table

    def get_semantic_similar_hpos(gs_hp_list, model_hp_list, ontology, threshold = 0.8):
        gs_hp_list_copy = set(copy.deepcopy(gs_hp_list))
        model_hp_list_copy = set(copy.deepcopy(model_hp_list))
        similar_pairs = []
        for model_hp in model_hp_list:
            model_hp_sims = {gs_hp: ontology.get_similarity(model_hp, gs_hp, sim_type = "lin", ic_type = "resnik") for gs_hp in gs_hp_list}.items()
            max_sim = max(model_hp_sims, key = lambda x: x[1]) if len(model_hp_sims) > 0 else ["No terms", 0]
            if max_sim[1] >= threshold:
                similar_pairs.append(f"{ontology.translate_id(max_sim[0])}-{ontology.translate_id(model_hp)}")
                gs_hp_list_copy.discard(max_sim[0])
                model_hp_list_copy.discard(model_hp)
        return similar_pairs, list(gs_hp_list_copy), list(model_hp_list_copy)

    ##### MAIN

    gs_names = {"do": "Disease Ontology", "ehrhart": "Ehrhart"}

    ontology = plotter.hash_vars["ontology"]
    omim_to_mondo_dict = plotter.hash_vars["omim_to_mondo_dict"]

    omim_code_to_name_dict = dict(plotter.hash_vars["omim_list"])
    pmid_to_title_dict = dict(plotter.hash_vars["pmid_titles"])
        
    all_both_data = ([["pmid", "score", "norm_rank", "abs_rank1", "abs_rank2", "omim_id", "dataset", "doc_type", "bench_type"]] +
                                        [ [row[0],row[1],row[2],row[3],row[4],row[5],row[9],row[10], "phenotype"] for row in plotter.hash_vars["all_phenotype_data"]] + 
                                        [ [row[0],row[1],row[2],row[3],row[4],row[5],row[7],row[8], "disease"] for row in plotter.hash_vars["all_disease_data"]]
    )
    formatter = {"do":"DO", "ehrhart": "Ehr", "abstracts": "Abs", "papers": "Full"}
    for row_idx in range(len(all_both_data)):
        for col_idx in range(len(all_both_data[0])):
            all_both_data[row_idx][col_idx] = formatter.get(all_both_data[row_idx][col_idx], all_both_data[row_idx][col_idx])     
    plotter.hash_vars["all_both_data"] = all_both_data

    top_k_header = [["topk", "pos", "dist", "dataset", "doc_type", "bench_type"]]
    #Preparing selected top-k data and cumulative distribution
    for bench_type in ["phenotype", "disease"]:
        for doc_type in ["Full", "Abs"]:
            for dataset in ["Ehr", "DO"]:
                #print(f"Processing {bench_type} {doc_type} {dataset}")
                abs_rankings = np.array(sorted([int(row[3]) for row in plotter.hash_vars['all_both_data'] if row[-3] == dataset and row[-2] == doc_type and row[-1] == bench_type]))
                cumms = [ np.mean(abs_rankings <= pos) for pos in range(1, len(abs_rankings)+1)]
                norm_pos = np.array(range(1, len(cumms)+1)) / len(cumms)
                abs_pos = [f"top{k}" for k in list(range(1, len(cumms)+1))] 
                cumm_dist_data = [list(pair)+[dataset, doc_type, bench_type] for pair in zip(abs_pos, norm_pos, cumms)]
                percentages= list((np.array([1,2,5,10]) * len(cumm_dist_data) / 100 ).round().astype("int32")-1)
                percentages_dict = dict(zip([1,2,5,10], percentages))

                if not plotter.hash_vars.get(f"cumm_dist"):
                    plotter.hash_vars[f"cumm_dist"] = top_k_header + cumm_dist_data
                    plotter.hash_vars[f"topk_long"] = top_k_header + [[                    f"{perc}%", cumm_dist_data[row_idx][2], cumm_dist_data[row_idx][3], cumm_dist_data[row_idx][4], cumm_dist_data[row_idx][5]] 
                                                                        for perc, row_idx in percentages_dict.items()]
                    plotter.hash_vars[f"topk_abs_long"] = top_k_header + [[cumm_dist_data[row_idx][0], cumm_dist_data[row_idx][2], cumm_dist_data[row_idx][3], cumm_dist_data[row_idx][4], cumm_dist_data[row_idx][5]] 
                                                                        for row_idx in [0,1,4,9]]                                                                            
                else:
                    plotter.hash_vars[f"cumm_dist"] += cumm_dist_data
                    plotter.hash_vars[f"topk_long"] += [[                    f"{perc}%", cumm_dist_data[row_idx][2], cumm_dist_data[row_idx][3], cumm_dist_data[row_idx][4], cumm_dist_data[row_idx][5]] 
                                                         for perc, row_idx in percentages_dict.items()]
                    plotter.hash_vars[f"topk_abs_long"] += [[cumm_dist_data[row_idx][0], cumm_dist_data[row_idx][2], cumm_dist_data[row_idx][3], cumm_dist_data[row_idx][4], cumm_dist_data[row_idx][5]] 
                                                         for row_idx in [0,1,4,9]]
    
    #Changing topk table from long format to specific wide format for the barplot
    topk_order = {"1%": 1, "2%": 2, "5%": 3, "10%": 4}
    topk_abs_order = {"top1": 1, "top2": 2, "top5": 3, "top10": 4}
    
    #print(plotter.hash_vars["topk_long"][:3])
    plotter.hash_vars[f"topk_wide"] = transform_from_long_to_wide(plotter.hash_vars["topk_long"][1:], topk_order)
    #print(plotter.hash_vars["topk_abs_long"][:3])
    plotter.hash_vars[f"topk_abs_wide"] = transform_from_long_to_wide(plotter.hash_vars["topk_abs_long"][1:], topk_abs_order)        

    #Getting profiles phenotype stats table and data suitable for rontoplot
    ehrhart_OMIMids_with_pmids =  set([row[0] for row in plotter.hash_vars["omim2_pubmed_profiles.txt"]])
    do_OMIMids_with_pmids =  set([row[0] for row in plotter.hash_vars["omim_pubmed_profiles.txt"]])

    ehrhart_profiles = {row[0]: row[1].split(",") for row in plotter.hash_vars["omim2_hpo_profiles.txt"] if row[0] in ehrhart_OMIMids_with_pmids}
    do_profiles = {row[0]: row[1].split(",") for row in plotter.hash_vars["omim_hpo_profiles.txt"] if row[0] in do_OMIMids_with_pmids}
    gs_profiles = {"ehrhart": ehrhart_profiles, "do": do_profiles}
    engine_profiles = {}
    profile_stats = {}

    for gs in gs_profiles:
        for typee in ["papers", "abstracts"]:
            print(f"Processing {gs} {typee}")
            profile_stats[gs+typee] = [["pmid", "omim_id", "matches", "non_matches_sum", "non_matches_dif" ,"disease_unique", "stEngine_unique"]]
            engine_profiles[gs+typee] = {row[0]: row[1].split(",") for row in plotter.hash_vars[f"{gs}_{typee}_llm_pmID_profiles.txt"]}
            plotter.hash_vars[f"{gs}_table_{typee}"] = [["title", "norm_score", "omim_id", "full_match_hpos", "semantic_similar_hpos", "disease_unique", "stEngine_unique"]]
            for row in [filtered for filtered in plotter.hash_vars["all_phenotype_data"] if typee in filtered and gs in filtered]:
                pmid, score, disease_id = row[0],row[2],row[5]
                gs_profile_hpos = [term for term in gs_profiles[gs][disease_id]]
                engine_profile_hpos = [term for term in engine_profiles[gs+typee][pmid.replace("PMID:", "")]]
                score = str(round(float(score),6))
                pmid = pmid_to_title_dict.get(pmid.replace("PMID:",""), pmid)
                disease_id = omim_code_to_name_dict.get(disease_id, disease_id)

                full_match_HPs_list = list(set(gs_profile_hpos).intersection(engine_profile_hpos))
                gs_soft_unique_list = list(set(gs_profile_hpos).difference(full_match_HPs_list))
                stEngine_soft_unique_list = list(set(engine_profile_hpos).difference(full_match_HPs_list))
                similar_HPs_list, gs_unique_list, stEngine_unique_list = get_semantic_similar_hpos(gs_soft_unique_list, stEngine_soft_unique_list, ontology)
                
                profile_stats[gs+typee].append([pmid, disease_id, len(full_match_HPs_list)+len(similar_HPs_list), len(gs_soft_unique_list)+len(stEngine_unique_list), 
                                        len(gs_soft_unique_list)-len(stEngine_unique_list) ,len(gs_unique_list), len(stEngine_unique_list)])

                full_match_HPs = ",".join([ontology.translate_id(term) for term in full_match_HPs_list])
                similar_HPs = ",".join(similar_HPs_list)
                gs_unique = ",".join([ontology.translate_id(term) for term in gs_unique_list])
                stEngine_unique = ",".join([ontology.translate_id(term) for term in stEngine_unique_list])
                plotter.hash_vars[f"{gs}_table_{typee}"].append([pmid, score, disease_id, full_match_HPs, similar_HPs, gs_unique, stEngine_unique])
        
            plotter.hash_vars[f"{gs}_profile_stats_{typee}"] = profile_stats[gs+typee]


dict_vars = dict(plotter.hash_vars['ont_sim_method_used'])
ont_sim_method_used = dict_vars['ONT_SIM_METHOD']
%>


<% plotter.set_header() %>

${ plotter.create_title(f'General stats and comparisons between gold standards. Ontological similarity method used: {ont_sim_method_used}', id='gs_general_from', hlevel=1, indexable=True, clickable=True, t_id='gs_general_to', clickable_text = '(Click me)') }
<% 
    gs_general = (plotter.renderize_child_template(plotter.get_internal_template('meta_general.txt'), gs=gs))
%>
${ plotter.create_collapsable_container('gs_general_to', gs_general, display="visible") }


%for gs in ["do", "ehrhart"]:
    ${ plotter.create_title(f'{gs_names[gs]} specific stats', id=f'{gs}_from', hlevel=1, indexable=True, clickable=True, t_id=f'{gs}_to', clickable_text = '(Click me)') }
    <% 
        gs_spec = (plotter.renderize_child_template(plotter.get_internal_template('meta_gs_spe.txt'), gs=gs, ontology=ontology, gs_profiles=gs_profiles, 
                    engine_profiles=engine_profiles, copy=copy, gs_names=gs_names))
    %>
    ${ plotter.create_collapsable_container(f'{gs}_to', gs_spec, display="visible") }
%endfor