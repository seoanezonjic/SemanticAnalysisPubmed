get_abstracts){
	resources: -n cal -c 50 -t '1-12:00:00' -m '400gb'
	#resources: -n cal -c 10 -t '7-00:00:00' -m '60gb'	
	. ~soft_bio_267/initializes/init_python

	export PATH=$code_path:$PATH #TODO: Remove later
	source $pyenv/bin/activate #TODO: Remove later
	
	n_cpus=$(([cpu] - 3))
	mkdir indexes
	?
	get_pubmed_index -i "$pubmed_path/*" -o indexes -t "pubmed_" -k $pubmed_chunksize -c $n_cpus -d $splitted $paper $equivalences

	#BEGIN:EXPERIMENTAL: TRYING TO PARALLELIZE 4 PUMBED FILLED BALANCED FOLDERS TO DRISTIBUTE THE EMBEDDING PROCESS IN 4 EXA NODES
	ls indexes > indexes_list
	for fold in `echo $tsv_folder | tr '-' ' '`; do
        mkdir $fold
	done

	total_lines=`wc -l < indexes_list`
	for i in `seq 1 $total_lines`; do
		modulo=$((i % $n_parallel_folders))
		filepath=`sed "$i"'q;d' indexes_list`
		ln -s $PWD/"indexes/"$filepath $PWD/$parallel_folders_basename$modulo/$filepath	
	done
	if [[ ! -d $parallel_folders_basename'0' || `ls $parallel_folders_basename'0' | wc -l` -eq 0 ]]; then exit 1 ; fi
	#END:EXPERIMENTAL

	cat *.err | grep stats | grep UserWarning > abstracts_debug_stats.txt
	cp abstracts_debug_stats.txt $tmp_path/abstracts_debug_stats.txt
}


query_abstracts_[$folders_to_parallelize]){
	resources: -n dgx -c 30 -t '6-00:00:00' -m '120gb' -A exclude=exa01;$n_gpus	
    #resources: -n dgx -c 120 -t '6-00:00:00' -m '360gb' -A exclude=exa01;$n_gpus
	. ~soft_bio_267/initializes/init_python

	export PATH=$code_path:$PATH #TODO: Remove later
	source $pyenv/bin/activate #TODO: Remove later

	export MKL_NUM_THREADS=$(([cpu] - 3)) #Pytorch option for CPU
	export OMP_NUM_THREADS=$(([cpu] - 3)) #Pytorch option for CPU
	gpu_csv=`echo $gpu_devices | tr '-' ','`
	echo "using gpu devices: $gpu_csv"

	mkdir semantic_scores
	query_basename=`basename $queries`
	?
	stEngine -m $model_name -p $current_model \
             -c get_abstracts)/(*)/"*.gz" -q $queries \
             -k $top_k -t $soft_min_similarity -o semantic_scores \
             -g $gpu_csv $splitted -v $use_gpu_for_sim_calc

	if [[ ! -s semantic_scores/$query_basename ]]; then exit 1; fi #exit if no results
	awk '{print $2 "\t" $1 "\t" $3 }' semantic_scores/$query_basename > soft_filtered_scores_raw
	rm semantic_scores/$query_basename
}

aggregate_results){
	resources: -n cal -c 4 -m 100G -t '0-10:00:00'
	. ~soft_bio_267/initializes/init_python	
	query_basename=`basename $queries`
	?
	cat !query_abstracts_!/soft_filtered_scores_raw | awk '{if($3 >= '$hard_min_similarity') print $0}' > hard_filtered_scores_raw
	collapse_same_HPs_inside_of_splitted_abstract.py -i hard_filtered_scores_raw -o hard_filtered_scores
	aggregate_column_data -i hard_filtered_scores -x 2 -a 1,3,4 > llm_term_profiles.txt
	aggregate_column_data -i hard_filtered_scores -x 1 -a 2,3,4 > llm_pmID_profiles_with_cosine_sim.txt

	cut -f 1,2 hard_filtered_scores | semtools -i - -O HPO -c -T "HP:0000118" --2cols --out2cols -o llm_pmID_profiles_cleaned_2cols.txt
	aggregate_column_data -i llm_pmID_profiles_cleaned_2cols.txt -x 1 -a 2 > llm_pmID_profiles_cleaned.txt

	if [ -s pubmed_metadata_full ]; then rm pubmed_metadata_full; fi
	for filename in get_abstracts)/indexes/* ; do
		zcat $filename | cut -f 1,3,4,5,6,7 >> pubmed_metadata_full
	done

	echo -e "pubmed_id\toriginal_file\tpublication_year" > pubmed_metadata
	intersect_columns -a pubmed_metadata_full -b llm_pmID_profiles_with_cosine_sim.txt -A 1 -B 1 -k c --full | cut -f 1,2,3,4,5,6 >> pubmed_metadata 
	#rm pubmed_metadata_full
	
	cp hard_filtered_scores $results_path/llm_filtered_scores
	cp llm_pmID_profiles_with_cosine_sim.txt $results_path/llm_pmID_profiles_with_cosine_sim.txt
	cp llm_pmID_profiles_cleaned.txt $results_path/llm_pmID_profiles.txt
	cp llm_term_profiles.txt $results_path/llm_term_profiles.txt
	cp pubmed_metadata $results_path/pubmed_metadata
}