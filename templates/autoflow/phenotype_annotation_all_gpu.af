filter_abstracts){
	resources: -n cal -c 10 -t '0-10:00:00' -m '100gb'
	#resources: -n cal -c 150 -t '1-10:00:00' -m '650gb'
	. ~soft_bio_267/initializes/init_python
	n_cpus=$(([cpu] - 3))
	indexes=$prepared_corpus
	?
	echo "Filtering abstracts"
	#BEGIN:EXPERIMENTAL: TRYING TO PARALLELIZE 4 PUMBED FILLED BALANCED FOLDERS TO DRISTIBUTE THE EMBEDDING PROCESS IN 4 EXA NODES
	ls $indexes > indexes_list
	for fold in `echo $tsv_folder | tr '-' ' '`; do
        mkdir $fold
	done

	total_lines=`wc -l < indexes_list`
	for i in `seq 1 $total_lines`; do
		modulo=$((i % $n_parallel_folders))
		filepath=`sed "$i"'q;d' indexes_list`
		ln -s $indexes/$filepath $PWD/$parallel_folders_basename$modulo/$filepath	
	done
	if [[ ! -d $parallel_folders_basename'1' || `ls $parallel_folders_basename'1' | wc -l` -eq 0 ]]; then exit 1 ; fi
	#END:EXPERIMENTAL

	cat logs/*.log | grep stats | sort -u > abstracts_debug_stats.txt
	cp abstracts_debug_stats.txt $tmp_path/abstracts_debug_stats.txt

	rm pmids_file_locator.txt
	for file in $indexes/*.gz; do
		filename=$(basename "$file")
		echo -e $filename"\t"`zcat $indexes/$filename | cut -f 1 | tr "\n" ","` >> pmids_file_locator.txt
	done
	echo $indexes > indexes_path
}

query_abstracts_[$folders_to_parallelize]){
	resources: -n dgx -m '40gb' -c 16 -t '2-00:00:00' -A $n_gpus	
	. ~soft_bio_267/initializes/init_python
	export MKL_NUM_THREADS=$(([cpu] - 3)) #Pytorch option for CPU
	export OMP_NUM_THREADS=$(([cpu] - 3)) #Pytorch option for CPU
	gpu_csv=`echo $gpu_devices | tr '-' ','`
	query_basename=`basename $queries`	
	mkdir semantic_scores
	?
	stEngine -m $model_name -p $current_model \
             -c filter_abstracts)/(*)/"*.gz" -q $queries \
             -k $top_k -t $soft_min_similarity -o semantic_scores \
             -g $gpu_csv $split_doc -v $use_gpu_for_sim_calc --chunk_size $text_balance_size

	if [[ ! -s semantic_scores/$query_basename ]]; then exit 1; fi #exit if no results
	awk '{print $2 "\t" $1 "\t" $3 }' semantic_scores/$query_basename > soft_filtered_scores_raw
	rm semantic_scores/$query_basename
}

aggregate_results){
	resources: -n cal -c 4 -m '500gb' -t '1-12:00:00'
	. ~soft_bio_267/initializes/init_python
	export PATH=$code_path:$PATH #TODO: Remove later
	query_basename=`basename $queries`
	ln -s filter_abstracts)/indexes_path indexes_path
	indexes_path=`cat indexes_path`
	?
	cat !query_abstracts_!/soft_filtered_scores_raw | awk '{if($3 >= '$hard_min_similarity') print $0}' > hard_filtered_scores_raw
	collapse_same_HPs_inside_of_splitted_abstract.py -i hard_filtered_scores_raw -o hard_filtered_scores
	aggregate_column_data -i hard_filtered_scores -x 2 -a 1,3,4 > llm_term_profiles.txt
	aggregate_column_data -i hard_filtered_scores -x 1 -a 2,3,4 > llm_pmID_profiles_with_cosine_sim.txt

	cut -f 1,2 hard_filtered_scores | semtools -i - -O HPO -c -T "HP:0000118" --2cols --out2cols -o profiles_cleaned_2cols.txt
	aggregate_column_data -i profiles_cleaned_2cols.txt -x 1 -a 2 > profiles_cleaned.txt
	remove_semtools_cleaned_hpos.py -i llm_pmID_profiles_with_cosine_sim.txt -f profiles_cleaned.txt -o llm_pmID_profiles_with_cosine_sim_cleaned.txt
	if [ ! -s llm_pmID_profiles_with_cosine_sim_cleaned.txt ]; then exit 1; fi #exit if no results

	if [ -s pubmed_metadata_full ]; then rm pubmed_metadata_full; rm pubmed_ids_and_titles_raw;fi
	for filename in $indexes_path/* ; do
		zcat $filename | cut -f 1,3,4,5,6,7 >> pubmed_metadata_full
		zcat $filename | cut -f 1,8,9,10 | awk 'BEGIN{FS="\t"}{if(NF == 4 && $1!="" && $2!="" && $3!="" && $4!="") print $0}' >> pubmed_ids_and_titles_raw
	done
	if [[ -s $title_blacklisted_words ]]; then
		#Line below outputs to pubmed_ids_and_titles
		sed 's/[^A-Za-z0-9]$//g' pubmed_ids_and_titles_raw | awk 'BEGIN{FS=OFS="\t"}{gsub(/^[ \t]+|[ \t]+$/, "", $3);gsub(/^[ \t]+|[ \t]+$/, "", $4);if(NF == 4 && $1!="" && $2!="" && $3!="" && $4!="") print $1,$2,$3,$4}' > pubmed_ids_and_titles
		
		#Filtering first blacklisted words in title
		filter_by_list -f pubmed_ids_and_titles -c 2 -t $title_blacklisted_words -o ./ --prefix blacklisted_ --not_exact_match
		cut -f 1 blacklisted_pubmed_ids_and_titles > blacklisted_pmids
		#Filtering now blacklisted words in article-category
		filter_by_list -f pubmed_ids_and_titles -c 4 -t $title_blacklisted_words -o ./ --prefix blacklisted_ --not_exact_match
		cut -f 1 blacklisted_pubmed_ids_and_titles >> blacklisted_pmids
		sort -u blacklisted_pmids > blacklisted_pmids_unique

		grep -vwf blacklisted_pmids_unique llm_pmID_profiles_with_cosine_sim_cleaned.txt > llm_pmID_profiles_with_cosine_sim_cleaned_filtered.txt
		#Making this in order to keep the same file name to copy below even if title_blacklisted_words is not used
		rm llm_pmID_profiles_with_cosine_sim_cleaned.txt
		mv llm_pmID_profiles_with_cosine_sim_cleaned_filtered.txt llm_pmID_profiles_with_cosine_sim_cleaned.txt
	else
		mv pubmed_ids_and_titles_raw pubmed_ids_and_titles
	fi
	cut -f 1,2 llm_pmID_profiles_with_cosine_sim_cleaned.txt > llm_pmID_profiles_cleaned.txt

	echo -e "pubmed_id\toriginal_file\tpublication_year" > pubmed_metadata
	intersect_columns -a pubmed_metadata_full -b llm_pmID_profiles_with_cosine_sim.txt -A 1 -B 1 -k c --full | cut -f 1,2,3,4,5,6 >> pubmed_metadata 
	#rm pubmed_metadata_full
	
	cp hard_filtered_scores $results_path/llm_filtered_scores
	cp llm_pmID_profiles_with_cosine_sim_cleaned.txt $results_path/llm_pmID_profiles_with_cosine_sim.txt
	cp llm_pmID_profiles_cleaned.txt $results_path/llm_pmID_profiles.txt
	cp llm_term_profiles.txt $results_path/llm_term_profiles.txt
	cp pubmed_metadata $results_path/pubmed_metadata
	cp pubmed_ids_and_titles_raw $results_path/pubmed_ids_and_titles
}