embbed_queries){
	resources: -n sd -c 30 -t '0-05:00:00'
	. ~soft_bio_267/initializes/init_python

	export MKL_NUM_THREADS=$(([cpu] - 3)) #Pytorch options for CPU
	export OMP_NUM_THREADS=$(([cpu] - 3))
	mkdir out
	?
	stEngine -m $model_name -p $current_model -q $queries -Q out -v
}

filter_abstracts){
	resources: -n cal -c 10 -t '0-10:00:00' -m '100gb'
	#resources: -n cal -c 150 -t '1-10:00:00' -m '650gb'
	. ~soft_bio_267/initializes/init_python
	n_cpus=$(([cpu] - 3))
	mkdir -p indexes
	indexes=$prepared_corpus
	?
	echo "Filtering abstracts"
	# CHECKING IF A PREFILTER PMIDs FILE IS GIVEN AND THEN SUBSET CORPUS TO ONLY CONTAIN THOSE PAPERS/ABSTRACTS
	# AND SPLITTING IN DIFFERENT FILES TO END WITH FILE SIZE EQUAL TO PUBMED_CHUNKSIZE
	pmids_prefilter_filepath="$prefilter_pmids_file"
	if [[ -n "$pmids_prefilter_filepath" ]]; then #Check if prefilter_pmids_file variable is not an empty string
		if [[ -s "$pmids_prefilter_filepath" ]]; then #Check if prefilter_pmids_file exists and is not empty
			indexes=$PWD/indexes
			zgrep --no-filename -wf $prefilter_pmids_file $prepared_corpus/*.gz > filtered_corpus_raw
			intersect_columns -a filtered_corpus_raw -b $prefilter_pmids_file -A 1 -B 1 --k c --full | cut -f 1-7 > filtered_corpus
			if [ ! -s filtered_corpus ]; then echo "ERROR:there is no filtered corpus"; exit 1; fi #exit if no results
			rm $indexes/*
			n_docs=`cat filtered_corpus | wc -l`
			for start_idx in $(seq 0 `echo "$n_docs/$after_filter_size" | bc`); do
				start_line=`echo "$start_idx*$after_filter_size+1" | bc`
				tail -n +$start_line filtered_corpus | head -n $after_filter_size | gzip > $indexes/pubmed_$start_idx.gz
			done
			if [ `ls $indexes | wc -l` -eq 0 ]; then echo "ERROR:there are no filtered indexes"; exit 1; fi #exit if no results
			
		
		
			#GETTING DOCS RAW STATS
			cut -f 1 filtered_corpus > CORPUS_PMIDS_TO_FILT
			cut -f 2 $diseases_with_pmid_and_phens_raw | tr "," "\n" | grep -wf CORPUS_PMIDS_TO_FILT > raw_pmids
			cut -f 1 $diseases_with_pmid_and_phens_raw > raw_diseases

			if [[ $doctype_placeholder_var == "abstracts" ]]; then #Raw stats are collected from unprocessed abstracts
				n_diseases=`cat raw_diseases | sort -u | wc -l`
				total_pmids=`cat raw_pmids | wc -l`
				unique_pmids=`cat raw_pmids | sort -u | wc -l`
				unique_pmids_proportion=`echo "scale=2; $unique_pmids/$total_pmids" | bc`
				pmids_per_disease=`echo "scale=2; $total_pmids/$n_diseases" | bc`
				pmids_in_one_disease=`cat raw_pmids | sort | uniq -c | sed -E "s/^[ ]+//g" | tr " " "\t" | awk 'BEGIN{FS=OFS="\t"}{if($1 == 1) print $0}' | wc -l`
				pmids_more_than_one_disease=`cat raw_pmids | sort | uniq -c | sed -E "s/^[ ]+//g" | tr " " "\t" | awk 'BEGIN{FS=OFS="\t"}{if($1 > 1) print $0}' | wc -l`
				mean_repetitions_pmid=`cat raw_pmids | sort | uniq -c | sed -E "s/^[ ]+//g" | tr " " "\t" | awk 'BEGIN{FS=OFS="\t"}{if($1 > 1) print $0}' | cut -f 1 | awk 'BEGIN{acc=0}{acc+=$1}END{print acc/NR}'`
				meta_tag_raw=`echo $metareport_tag | sed -E "s/abstracts|papers/raw/g"`
				echo -e "metareport_tag\tn_diseases\ttotal_pmids\tunique_pmids\tunique_pmids_proportion\tpmids_per_disease\tpmids_in_one_disease\tpmids_more_than_one_disease\tmean_repetitions_pmid" > goldstandard_stats
				echo -e "$meta_tag_raw\t$n_diseases\t$total_pmids\t$unique_pmids\t$unique_pmids_proportion\t$pmids_per_disease\t$pmids_in_one_disease\t$pmids_more_than_one_disease\t$mean_repetitions_pmid" >> goldstandard_stats
				meta_tag_reformatted=`echo $meta_tag_raw | tr "." "_"`
				cat goldstandard_stats > $metareport_results_path/GS_COUNTS_STATS/$meta_tag_reformatted'_phenotype'
			fi
		fi
	fi

	#PARALLELIZE "N" PUMBED FILLED BALANCED FOLDERS TO DRISTIBUTE THE EMBEDDING PROCESS IN DIFFERENT EXA NODES
	for fold in `echo $tsv_folder | tr '-' ' '`; do
        mkdir $fold
	done
	ls $indexes > indexes_list
	total_lines=`wc -l < indexes_list`
	for i in `seq 1 $total_lines`; do
		modulo=$((i % $n_parallel_folders))
		filepath=`sed "$i"'q;d' indexes_list`
		ln -s $indexes/$filepath $PWD/$parallel_folders_basename$modulo/$filepath	
	done
	if [[ ! -d $parallel_folders_basename'0' || `ls $parallel_folders_basename'0' | wc -l` -eq 0 ]]; then echo "ERROR:files were not correctly distributed"; exit 1; fi

	echo $indexes > indexes_path
	cat logs/*.log | grep stats | sort -u > abstracts_debug_stats.txt
	cp abstracts_debug_stats.txt $tmp_path/abstracts_debug_stats.txt
}

embbed_abstracts_[$folders_to_parallelize]){
	resources: -n dgx -c 10 -t '1-12:00:00' -m '360gb' -A $n_gpus
	source ~soft_bio_267/initializes/init_pytorch  #. ~soft_bio_267/initializes/init_python
	export MKL_NUM_THREADS=$(([cpu] - 3)) #Pytorch options for CPU
	export OMP_NUM_THREADS=$(([cpu] - 3))
	mkdir embeddings
	gpu_csv=`echo $gpu_devices | tr '-' ','`
	echo "using gpu devices: $gpu_csv"
	?
	stEngine -m $model_name -p $current_model -c filter_abstracts)/(*)/"*.gz" -C embeddings -g $gpu_csv -v $split_doc --chunk_size $text_balance_size
	if [ `ls embeddings | wc -l` -eq 0 ]; then exit 1; fi
}

query_abstracts_[$folders_to_parallelize]){
	resources: -n cal -c 128 -t '1-10:00:00' -m '439gb'
	#resources: -n cal -c 150 -m 650G
	. ~soft_bio_267/initializes/init_python
	export MKL_NUM_THREADS=$(([cpu] - 3)) #Pytorch options for CPU
	export OMP_NUM_THREADS=$(([cpu] - 3))
	mkdir semantic_scores
	query_basename=`basename $queries`
	?
	stEngine -C !embbed_abstracts_*!"/embeddings/*" -Q embbed_queries)"/out/"$query_basename".pkl" -k $top_k -o semantic_scores -v -t $soft_min_similarity
	if [[ ! -s semantic_scores/$query_basename ]]; then exit 1; fi #exit if no results
	awk '{print $2 "\t" $1 "\t" $3 }' semantic_scores/$query_basename > soft_filtered_scores_raw
	rm semantic_scores/$query_basename
}

aggregate_results){
	resources: -n cal -c 4 -m '500gb' -t '0-12:00:00'
	. ~soft_bio_267/initializes/init_python
	export PATH=$code_path:$PATH
	query_basename=`basename $queries`
	rm indexes_path
	ln -s filter_abstracts)/indexes_path indexes_path
	indexes_path=`cat indexes_path`
	?
	cat !query_abstracts_!/soft_filtered_scores_raw | awk '{if($3 >= '$hard_min_similarity') print $0}' > hard_filtered_scores_raw
	collapse_same_HPs_inside_of_splitted_abstract.py -i hard_filtered_scores_raw -o hard_filtered_scores
	aggregate_column_data -i hard_filtered_scores -x 2 -a 1,3,4 > llm_term_profiles.txt
	aggregate_column_data -i hard_filtered_scores -x 1 -a 2,3,4 > llm_pmID_profiles_with_cosine_sim.txt

	cut -f 1,2 hard_filtered_scores | semtools -i - -O HPO -c -T "HP:0000118" --2cols --out2cols -o profiles_cleaned_2cols.txt
	aggregate_column_data -i profiles_cleaned_2cols.txt -x 1 -a 2 > profiles_cleaned.txt
	remove_semtools_cleaned_hpos.py -i llm_pmID_profiles_with_cosine_sim.txt -f profiles_cleaned.txt -o llm_pmID_profiles_with_cosine_sim_cleaned.txt
	if [ ! -s llm_pmID_profiles_with_cosine_sim_cleaned.txt ]; then exit 1; fi #exit if no results

	if [ -s pubmed_metadata_full ]; then rm pubmed_metadata_full; rm pubmed_ids_and_titles_raw; fi
	if [[ -z "$indexes_path" ]]; then echo "ERROR: indexes path variable has not been correctly defined"; exit 1; fi
	for filename in $indexes_path/* ; do
		zcat $filename | cut -f 1,3,4,5,6,7 >> pubmed_metadata_full
		zcat $filename | cut -f 1,8,9,10 | awk 'BEGIN{FS="\t"}{if(NF == 4 && $1!="" && $2!="" && $3!="" && $4!="") print $0}' >> pubmed_ids_and_titles_raw
	done
	if [[ -s $title_blacklisted_words ]]; then
		#Line below outputs to pubmed_ids_and_titles
		sed 's/[^A-Za-z0-9]$//g' pubmed_ids_and_titles_raw | awk 'BEGIN{FS=OFS="\t"}{gsub(/^[ \t]+|[ \t]+$/, "", $3);gsub(/^[ \t]+|[ \t]+$/, "", $4);if(NF == 4 && $1!="" && $2!="" && $3!="" && $4!="") print $1,$2,$3,$4}' > pubmed_ids_and_titles
		
		#Filtering first blacklisted words in title
		filter_by_list -f pubmed_ids_and_titles -c 2 -t $title_blacklisted_words -o ./ --prefix blacklisted_ --not_exact_match
		cut -f 1 blacklisted_pubmed_ids_and_titles > blacklisted_pmids
		#Filtering now blacklisted words in article-category
		filter_by_list -f pubmed_ids_and_titles -c 4 -t $title_blacklisted_words -o ./ --prefix blacklisted_ --not_exact_match
		cut -f 1 blacklisted_pubmed_ids_and_titles >> blacklisted_pmids
		sort -u blacklisted_pmids > blacklisted_pmids_unique

		grep -vwf blacklisted_pmids_unique llm_pmID_profiles_with_cosine_sim_cleaned.txt > llm_pmID_profiles_with_cosine_sim_cleaned_filtered.txt
		#Making this in order to keep the same file name to copy below even if title_blacklisted_words is not used
		rm llm_pmID_profiles_with_cosine_sim_cleaned.txt
		mv llm_pmID_profiles_with_cosine_sim_cleaned_filtered.txt llm_pmID_profiles_with_cosine_sim_cleaned.txt
	else
		mv pubmed_ids_and_titles_raw pubmed_ids_and_titles
	fi
	cut -f 1,2 llm_pmID_profiles_with_cosine_sim_cleaned.txt > llm_pmID_profiles_cleaned.txt

	if [[ $add_random_papers == "yes" ]]; then
		#total_profiles_number=`cat $file_to_get_random | wc -l`
		gold_profiles_number=`cat llm_pmID_profiles_cleaned.txt | wc -l`
		random_docs_number=`echo "$gold_profiles_number * $gs_vs_random_ratio" | bc`
		echo "Number of gold standard files: $gold_profiles_number. Number of random files: $random_docs_number"
		#random_profiles_indexes=`shuf -i 1-$total_profiles_number -n $random_docs_number | tr "\n" " "`
		#cat $file_to_get_random | awk -v rows="$random_profiles_indexes" 'BEGIN {split(rows, a); for (i in a) {map[a[i]] = 1}} FNR in map {print $0}' > random_chosen_profiles.txt
		#cat random_chosen_profiles.txt >> llm_pmID_profiles_cleaned.txt

		cat $file_to_get_random | cut -f 1 > all_pmids
		get_random_negatives.py --all_pmids all_pmids --pmids_to_skip $prefilter_pmids_file --randoms_number $random_docs_number > random_pmids_to_add
		cat $file_to_get_random | grep -wf random_pmids_to_add | awk 'BEGIN{OFS="\t"}{print $1"rand",$2}' > random_profiles.txt
	fi

	cp hard_filtered_scores $results_path/llm_filtered_scores
	cp llm_pmID_profiles_with_cosine_sim_cleaned.txt $results_path/llm_pmID_profiles_with_cosine_sim.txt
	cp llm_pmID_profiles_cleaned.txt $results_path/llm_pmID_profiles.txt
	cat random_profiles.txt llm_pmID_profiles_cleaned.txt > $results_path/llm_pmID_profiles_with_randoms.txt
	cp llm_term_profiles.txt $results_path/llm_term_profiles.txt
	cp pubmed_metadata_full $results_path/pubmed_metadata
	cp pubmed_ids_and_titles_raw $results_path/pubmed_ids_and_titles
}
